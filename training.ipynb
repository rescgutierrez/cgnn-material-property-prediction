{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dY-BBFAkNX5"
   },
   "outputs": [],
   "source": [
    "# !pip install dgl-cu102 hyperopt ase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "oMgTYqFdi1Xc",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "45da74ce-7355-4918-f84e-16c3f737248b"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from crystals_DatasetInstance_graphbatch_encode3 import CrystalsDataset\n",
    "\n",
    "from dgl.nn.pytorch.glob import SumPooling\n",
    "import dgl\n",
    "\n",
    "from hyperopt import (hp, tpe, fmin, anneal,\n",
    "                      mix, partial, STATUS_OK, STATUS_FAIL)\n",
    "from hyperopt.base import Trials\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "from functools import reduce\n",
    "from time import perf_counter\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import graph\n",
    "import dgl.function as fn\n",
    "\n",
    "from datetime import datetime\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from collections import deque\n",
    "import wandb\n",
    "\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "pCCaH7Kci1Xt",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = th.cuda.is_available()\n",
    "device = th.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "th.backends.cudnn.benchmark = True\n",
    "\n",
    "class CG_CNN_Layer(nn.Module):\n",
    "    def __init__(self, in_feats):\n",
    "        super(CG_CNN_Layer, self).__init__()\n",
    "        self.linearf = nn.Linear(2 * in_feats + 10, in_feats)\n",
    "        self.linears = nn.Linear(2 * in_feats + 10, in_feats)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.linearf.reset_parameters()\n",
    "        self.linears.reset_parameters()\n",
    "\n",
    "    def CGCNN_message(self, edges):\n",
    "        msg = th.cat((edges.src['env'], edges.dst['env'],\n",
    "                      edges.data['dist']), dim=-1)\n",
    "        msg = (th.sigmoid(self.linearf(msg))) * (F.softplus(self.linears(msg)))\n",
    "        return {'m': msg}\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        with g.local_scope():\n",
    "            g.ndata['env'] = features\n",
    "            g.update_all(message_func=self.CGCNN_message,\n",
    "                         reduce_func=fn.sum(msg='m',out='m_sum'))\n",
    "            env = g.ndata['env'] + g.ndata['m_sum']\n",
    "            return env\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feats, n_conv, neuron_ratios, activation):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = CG_CNN_Layer(in_feats)\n",
    "        if n_conv>1:\n",
    "            self.conv2 = CG_CNN_Layer(in_feats)\n",
    "            if n_conv>2:\n",
    "                self.conv3 = CG_CNN_Layer(in_feats)\n",
    "        self.n_conv = n_conv\n",
    "        # The commented part of the architecture is for other uses cases\n",
    "#         self.conv_linear = nn.Linear(in_feats)\n",
    "#         self.mlp11 = nn.Linear(in_feats, neuron_ratios[0][0] * in_feats)\n",
    "#         self.mlp12 = nn.Linear(\n",
    "#             neuron_ratios[0][0] * in_feats, neuron_ratios[0][1] * in_feats)\n",
    "#         self.mlp13 = nn.Linear(neuron_ratios[0][1] * in_feats, in_feats)\n",
    "        self.mlp21 = nn.Linear(in_feats, neuron_ratios[1][0] * in_feats)\n",
    "        self.mlp22 = nn.Linear(neuron_ratios[1][0] * in_feats, neuron_ratios[1][1] * in_feats)\n",
    "        self.mlp23 = nn.Linear(neuron_ratios[1][1] * in_feats, 1)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, graphs):\n",
    "\n",
    "        out = self.conv1(graphs, graphs.ndata['Z'])\n",
    "        if self.n_conv>1:\n",
    "            out = self.conv2(graphs, out)\n",
    "            if self.n_conv>2:\n",
    "                out = self.conv3(graphs, out)\n",
    "#         out = self.mlp13(self.activation(self.mlp12(self.activation(self.mlp11(out)))))\n",
    "        # out = self.pooling(graphs, out) / graphs.batch_num_nodes()\n",
    "        with graphs.local_scope():\n",
    "            graphs.ndata['env'] = out\n",
    "            out = dgl.readout.mean_nodes(graphs, 'env')\n",
    "            out = self.mlp23(self.activation(self.mlp22(self.activation(self.mlp21(out)))))\n",
    "            return out\n",
    "\n",
    "class RMSLELoss(th.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RMSLELoss, self).__init__()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        ret = th.log((x + 1) / (y + 1))\n",
    "        ret = th.norm(ret)/th.sqrt(th.tensor(ret.shape[0], dtype = th.float, device= device))\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset train, valid, test partitions\n",
    "idxs = np.arange(0, 2400, 1)\n",
    "spl1 = ShuffleSplit(\n",
    "    n_splits=1, test_size=0.20, random_state=0).split(idxs)\n",
    "spl1 = tuple(spl1)\n",
    "train_idxs, valid_idxs = spl1[0][0], spl1[0][1]\n",
    "\n",
    "spl2 = ShuffleSplit(\n",
    "    n_splits=1, test_size=1. / 7., random_state=0).split(train_idxs)\n",
    "spl2 = tuple(spl2)\n",
    "train_idxs, test_idxs = spl2[0][0], spl2[0][1]\n",
    "del(idxs)\n",
    "\n",
    "\n",
    "root = '/home/raul/Documents/Máster Data Science/Tesis/materials/crystal_graph_cnn/'\n",
    "# root = ''\n",
    "n_elements = 49\n",
    "\n",
    "# Datasets\n",
    "training_set, validation_set, test_set = tuple(map(CrystalsDataset, [train_idxs, valid_idxs, test_idxs], \n",
    "                                                   [root]*3, [n_elements]*3))\n",
    "\n",
    "num_workers = cpu_count()\n",
    "\n",
    "def collate(samples):\n",
    "    # For batch formation\n",
    "    graphs, targets, indexes = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    batched_targets = th.tensor(targets)\n",
    "    batched_indexes = th.tensor(indexes)\n",
    "    return batched_graph, batched_targets, batched_indexes\n",
    "\n",
    "test_generator = th.utils.data.DataLoader(test_set,\n",
    "                                          collate_fn=collate,\n",
    "                                         batch_size = 1,\n",
    "                                         num_workers= num_workers)\n",
    "validation_generator = th.utils.data.DataLoader(validation_set,\n",
    "                                                    batch_size = len(valid_idxs),\n",
    "                                                    collate_fn=collate,\n",
    "                                                   num_workers= num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "1oQsWYR3i1X5",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "329e9fbd-d5b4-4985-b6a6-6f3b1846a7e4"
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "\n",
    "    'architecture': {\n",
    "        'neuron_ratios': [hp.choice('neuron_ratios0', [[3, 2],\n",
    "                                                     [4, 2],\n",
    "                                                     [5, 2]]),\n",
    "                         hp.choice('neuron_ratios1', [[10, 20],\n",
    "                                                     [50, 100],\n",
    "                                                     [20, 10],\n",
    "                                                     [100, 50],\n",
    "                                                     [100,200],\n",
    "                                                     [200,100]])],\n",
    "        'n_conv': hp.choice('n_conv', [1, 2, 3]),\n",
    "        'activation': hp.choice('', [nn.ReLU, nn.LeakyReLU, nn.SELU])\n",
    "    },\n",
    "    'batch_size': hp.choice('batch_size',\n",
    "#                                 [2, 4, 8, 16, 32, 64, len(train_idxs)]),\n",
    "                            [len(train_idxs)]),\n",
    "    'optimizer_params': {\n",
    "\n",
    "        \n",
    "        'lr':\n",
    "            hp.qloguniform('learning_rate',\n",
    "                           np.log(1e-4), np.log(1e-1), 0.0005),\n",
    "        'weight_decay': hp.qloguniform('l2_reg_parameter',\n",
    "                           np.log(1e-4), np.log(5), 0.0005),\n",
    "        'betas': (hp.uniform('beta1', 0 , 0.9), hp.choice('beta2', [0.99,0.999,0.9999])),\n",
    "        'amsgrad': hp.choice('amsgrad', [True, False]),\n",
    "            \n",
    "        },\n",
    "    }\n",
    "\n",
    "mix_algo = partial(mix.suggest, p_suggest=[  # (0.10, rand.suggest),\n",
    "    (0.90, tpe.suggest),\n",
    "    (0.10, anneal.suggest)])\n",
    "tpe_algorithm = mix_algo\n",
    "\n",
    "obj_params = sample(space)\n",
    "# obj_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Xb0ku_ori1YL",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture': {'activation': torch.nn.modules.activation.ReLU,\n",
       "  'n_conv': 1,\n",
       "  'neuron_ratios': ((3, 2), (10, 20))},\n",
       " 'batch_size': 1645,\n",
       " 'optimizer_params': {'amsgrad': False,\n",
       "  'betas': (0.20671238439097625, 0.9999),\n",
       "  'lr': 0.0125,\n",
       "  'weight_decay': 0.0025}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Xb0ku_ori1YL",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/raul/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bright-sun-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rescgutierrez/GraphCNN\" target=\"_blank\">https://wandb.ai/rescgutierrez/GraphCNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/rescgutierrez/GraphCNN/runs/83g4tbd4\" target=\"_blank\">https://wandb.ai/rescgutierrez/GraphCNN/runs/83g4tbd4</a><br/>\n",
       "                Run data is saved locally in <code>/home/raul/Documents/Máster Data Science/Tesis/materials/crystal_graph_cnn/tests/t13/wandb/run-20201205_192048-83g4tbd4</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(83g4tbd4)</h1><p></p><iframe src=\"https://wandb.ai/rescgutierrez/GraphCNN/runs/83g4tbd4\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f151d2bfa30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"GraphCNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Xb0ku_ori1YL",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "training_generator = th.utils.data.DataLoader(training_set,\n",
    "                                          batch_size = obj_params['batch_size'],\n",
    "                                          collate_fn=collate,\n",
    "                                         num_workers= num_workers,\n",
    "                                         shuffle = True)\n",
    "\n",
    "\n",
    "in_feats = 14\n",
    "net = Net(in_feats=in_feats, **obj_params['architecture']).to(device)\n",
    "opt = th.optim.Adam(net.parameters(), **obj_params['optimizer_params'])\n",
    "loss = th.nn.MSELoss()\n",
    "v_loss = th.nn.MSELoss()\n",
    "max_epochs = 300\n",
    "verbose = True\n",
    "nan_count = []\n",
    "min_ep_v_loss = 100\n",
    "epoch_time = []\n",
    "nan_batches = 0\n",
    "losses = {'train':[], 'valid':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Xb0ku_ori1YL",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f151d3199d0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(net, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Xb0ku_ori1YL",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Byte but got scalar type Float for sequence element 2 in sequence argument at position #1 'tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a00a140f028f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Model computations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mj\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-fca984b036f9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graphs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_conv\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-fca984b036f9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'env'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             g.update_all(message_func=self.CGCNN_message,\n\u001b[0m\u001b[1;32m     28\u001b[0m                          reduce_func=fn.sum(msg='m',out='m_sum'))\n\u001b[1;32m     29\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'env'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm_sum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.8/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.8/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.8/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0medge_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfdedge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mdst_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfddst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mudf_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mudf_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.8/site-packages/dgl/runtime/scheduler.py\u001b[0m in \u001b[0;36m_mfunc_wrapper\u001b[0;34m(src_data, edge_data, dst_data)\u001b[0m\n\u001b[1;32m    970\u001b[0m                            \u001b[0msrc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                            canonical_etype=canonical_etype)\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mebatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0m_mfunc_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFUNC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mfunc_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEDGE_UDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mfunc_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdedge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfddst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-fca984b036f9>\u001b[0m in \u001b[0;36mCGCNN_message\u001b[0;34m(self, edges)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mCGCNN_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         msg = th.cat((edges.src['env'], edges.dst['env'],\n\u001b[0m\u001b[1;32m     20\u001b[0m                       edges.data['dist']), dim=-1)\n\u001b[1;32m     21\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinearf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Byte but got scalar type Float for sequence element 2 in sequence argument at position #1 'tensors'"
     ]
    }
   ],
   "source": [
    "# Loop over epochs\n",
    "for epoch in range(5):\n",
    "    t_start = perf_counter()\n",
    "    ep_t_loss = 0\n",
    "    ep_v_loss = 0\n",
    "    # Training\n",
    "    j=0\n",
    "    with th.autograd.detect_anomaly():\n",
    "        for local_batch, local_targets, local_indexes in training_generator:\n",
    "            j+=1\n",
    "            # Transfer to GPU\n",
    "            local_batch, local_targets = local_batch.to(\n",
    "                device), local_targets.to(device)\n",
    "\n",
    "            # Model computations\n",
    "            try:\n",
    "                pred = net(local_batch)\n",
    "            except KeyError:\n",
    "                j-=1\n",
    "                nan_batches+=1\n",
    "                opt.zero_grad()\n",
    "                continue\n",
    "            t_loss_batch = loss(pred.float(), local_targets.float())\n",
    "            ep_t_loss+=t_loss_batch.item()\n",
    "            t_loss_batch.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    ep_t_loss=ep_t_loss/j\n",
    "    losses['train'].append(ep_t_loss)\n",
    "\n",
    "    t_end = perf_counter()\n",
    "    epoch_time.append(t_end - t_start)\n",
    "    if epoch % 10 == 0 and verbose:\n",
    "        print(f\"step #{epoch} | ep_train_loss = {np.sqrt(ep_t_loss):.4f}\"\n",
    "             f\" | epoch_time = {t_end - t_start:.2f}\"\n",
    "             f\" | lost_batches = {nan_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
