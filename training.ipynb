{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dY-BBFAkNX5"
   },
   "outputs": [],
   "source": [
    "# !pip install dgl-cu102 hyperopt ase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oMgTYqFdi1Xc",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "45da74ce-7355-4918-f84e-16c3f737248b"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from dataset import CrystalsDataset, partitions\n",
    "from network import CG_CNN_Layer, Net\n",
    "\n",
    "from dgl.nn.pytorch.glob import SumPooling\n",
    "import dgl\n",
    "\n",
    "from functools import reduce\n",
    "from time import perf_counter\n",
    "\n",
    "import torch as th\n",
    "\n",
    "from datetime import datetime\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "import torchsummary\n",
    "\n",
    "os.environ['DGLBACKEND'] = \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "pCCaH7Kci1Xt",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = th.cuda.is_available()\n",
    "device = th.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "th.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, valid_idxs, test_idxs = partitions()\n",
    "\n",
    "# Datasets\n",
    "training_set, validation_set, test_set = tuple(map(CrystalsDataset, [train_idxs, valid_idxs, test_idxs], \n",
    "                                                    ))\n",
    "\n",
    "num_workers = cpu_count()\n",
    "\n",
    "def collate(samples):\n",
    "    # For batch formation\n",
    "    graphs, targets, indexes = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    batched_targets = th.tensor(targets)\n",
    "    batched_indexes = th.tensor(indexes)\n",
    "    return batched_graph, batched_targets, batched_indexes\n",
    "\n",
    "test_generator = th.utils.data.DataLoader(test_set,\n",
    "                                          collate_fn=collate,\n",
    "                                         batch_size = 1,\n",
    "                                         num_workers= num_workers)\n",
    "validation_generator = th.utils.data.DataLoader(validation_set,\n",
    "                                                    batch_size = len(valid_idxs),\n",
    "                                                    collate_fn=collate,\n",
    "                                                   num_workers= num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Xb0ku_ori1YL",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "obj_params = {'architecture': {'activation': th.nn.modules.activation.ReLU,\n",
    "  'n_conv': 1,\n",
    "  'neuron_ratios': ((3, 2), (20, 10))},\n",
    " 'batch_size': 32,\n",
    " 'optimizer_params': {'amsgrad': False,\n",
    "  'betas': (0.9, 0.9999),\n",
    "  'lr': 0.01,\n",
    "  'weight_decay': 0.0025}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Xb0ku_ori1YL",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architecture': {'activation': torch.nn.modules.activation.ReLU,\n",
       "  'n_conv': 1,\n",
       "  'neuron_ratios': ((3, 2), (20, 10))},\n",
       " 'batch_size': 32,\n",
       " 'optimizer_params': {'amsgrad': False,\n",
       "  'betas': (0.9, 0.9999),\n",
       "  'lr': 0.01,\n",
       "  'weight_decay': 0.0025}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Xb0ku_ori1YL",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "training_generator = th.utils.data.DataLoader(training_set,\n",
    "                                          batch_size = obj_params['batch_size'],\n",
    "                                          collate_fn=collate,\n",
    "                                         num_workers= num_workers,\n",
    "                                         shuffle = True)\n",
    "\n",
    "\n",
    "in_feats = 14\n",
    "net = Net(in_feats=in_feats, **obj_params['architecture']).to(device)\n",
    "opt = th.optim.Adam(net.parameters(), **obj_params['optimizer_params'])\n",
    "loss = th.nn.MSELoss()\n",
    "v_loss = th.nn.MSELoss()\n",
    "max_epochs = 300\n",
    "verbose = True\n",
    "nan_count = []\n",
    "min_ep_v_loss = 100\n",
    "epoch_time = []\n",
    "nan_batches = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Xb0ku_ori1YL",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    t_start = perf_counter()\n",
    "    ep_t_loss = 0\n",
    "    ep_v_loss = 0\n",
    "    j=0\n",
    "    with th.autograd.detect_anomaly():\n",
    "        for local_batch, local_targets, local_indexes in training_generator:\n",
    "            j+=1\n",
    "            # Transfer to GPU\n",
    "            local_batch, local_targets = local_batch.to(\n",
    "                device), local_targets.to(device)\n",
    "\n",
    "            # Model computations\n",
    "            try:\n",
    "                pred = net(local_batch)\n",
    "            except KeyError:\n",
    "                j-=1\n",
    "                nan_batches+=1\n",
    "                opt.zero_grad()\n",
    "                continue\n",
    "            t_loss_batch = loss(pred.float(), local_targets.float())\n",
    "            ep_t_loss+=t_loss_batch.item()\n",
    "            t_loss_batch.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    ep_t_loss=ep_t_loss/j\n",
    "    losses['train'].append(ep_t_loss)\n",
    "\n",
    "    t_end = perf_counter()\n",
    "    epoch_time.append(t_end - t_start)\n",
    "    if epoch % 10 == 0 and verbose:\n",
    "        print(f\"step #{epoch} | ep_train_loss = {np.sqrt(ep_t_loss):.4f}\"\n",
    "             f\" | epoch_time = {t_end - t_start:.2f}\"\n",
    "             f\" | lost_batches = {nan_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
